{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff24a41d",
   "metadata": {},
   "source": [
    "# BERT 전이학습\n",
    "\n",
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e880e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "# NSMC (네이버 영화리뷰) 데이터 다운로드\n",
    "ratings_train_path = get_file('ratings_train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
    "ratings_test_path = get_file('ratings_test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875b74b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings_train_df = pd.read_csv(ratings_train_path, sep='\\t')  # 학습 데이터 로드\n",
    "ratings_test_df = pd.read_csv(ratings_test_path, sep='\\t')\n",
    "\n",
    "display(ratings_train_df.head())  # 상위 5개 출력\n",
    "display(ratings_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc28f2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of               id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[149995 rows x 3 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             id                                           document  label\n",
       "0      6270596                                                굳 ㅋ      1\n",
       "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
       "...        ...                                                ...    ...\n",
       "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
       "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
       "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
       "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
       "49999  6070594                                         마무리는 또 왜이래      0\n",
       "\n",
       "[49997 rows x 3 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_train_df = ratings_train_df.dropna(how='any')  # 학습 데이터 결측치 포함 행 제거\n",
    "ratings_test_df = ratings_test_df.dropna(how='any')\n",
    "\n",
    "display(ratings_train_df.info)\n",
    "display(ratings_test_df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f1af2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 0    7512\n",
       " 1    7488\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 0    2532\n",
       " 1    2468\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train_df = ratings_train_df.sample(n=15000, random_state=0)  # 학습 데이터 15000개 무작위 추출 (재현성 고정)\n",
    "ratings_test_df = ratings_test_df.sample(n=5000, random_state=0)\n",
    "\n",
    "# 라벨 (0/1) 개수 분포 확인\n",
    "ratings_train_df['label'].value_counts(), ratings_test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c91d721c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 15000, 5000, 5000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트/라벨을 리스트로 변환 (학습/테스트 분리)\n",
    "X_train = ratings_train_df['document'].values.tolist()  # 학습 입력 문장(document) 컬럼을 리스트로 변환\n",
    "y_train = ratings_train_df['label'].values.tolist()\n",
    "\n",
    "X_test = ratings_test_df['document'].values.tolist()    # 테스트 입력 문장(document) 컬럼을 리스트로 변환\n",
    "y_test = ratings_test_df['label'].values.tolist()\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41697a3",
   "metadata": {},
   "source": [
    "### 토크나이저/모델 준비\n",
    "\n",
    "- bert 한국어 버전 사전학습 모델 klue/bert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ed283e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained('klue/bert-base')          # 사전학습 KLUE BERT 모델 로드 (가중치 포함)\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')  # 사전학습 KLUE BERT 토크나이저 로드 (토큰화 규칙/어휘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e875802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length  # 512 토큰을 넘으면 토큰화시 자름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f86f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=142, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])],\n",
       " [Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       "  Encoding(num_tokens=118, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = tokenizer(X_train, padding=True, truncation=True)  # 가장 긴 문장을 가진 토큰 기준으로 맞춰진다.\n",
    "X_test = tokenizer(X_test, padding=True, truncation=True)\n",
    "\n",
    "X_train[:5], X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1800, 2178, 860, 3629, 16516, 2031, 18, 18, 18, 14242, 2205, 2062, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train['input_ids'][0])        # 토큰 -> 정수ID로 변환된 시퀀스\n",
    "print(X_train['attention_mask'][0])   # 실제 토큰=1, 패딩=0으로 구분한 마스크\n",
    "print(X_train['token_type_ids'][0])   # 문장 구분 ID (단일 문장은 모두 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425f0711",
   "metadata": {},
   "source": [
    "### 데이터 파이프라인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f8d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)    # tokenizer 반환 객체 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4641d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 의 tf.datea.Dataset 생성 (BERT 입력 + 라벨 묶기)\n",
    "import tensorflow as tf\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((dict(X_train), y_train))  # 토큰화 dict + 라벨 = Dataset 변환 (학습용)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((dict(X_test), y_test))     # 토큰화 dict + 라벨 = Dataset 변환 (테스트용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a46eaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 : 셔플 -> 미니배치 -> 프리배치로 파이프라인 최적화\n",
    "train_dataset = train_ds.shuffle(10000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "# 테스트 : 미니배치 -> 프리배치로 파이프라인 최적화\n",
    "test_dataset = test_ds.batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b884a7f",
   "metadata": {},
   "source": [
    ".prefetch(tf.data.AUTOTUNE) : 계산이랑 데이터 준비를 겹쳐서 미리 준비해둔다. (적당한 갯수는 Tensorflow에서 알아서 계산한다.)  \n",
    "-> [데이터 로딩 + 모델 계산] -> [데이터 로딩 + 모델 계산]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a248a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.33.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.4.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2026.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (12.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\playdata\\nlp\\nlp_venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.1 MB/s  0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f40ce456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# KLUE BERT 분류 모델 로드\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "# 2클래스 분류용 TF BERT 로드 (Pytorch 가중치 변환)\n",
    "model = TFBertForSequenceClassification.from_pretrained('klue/bert-base', num_labels=2, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c959ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "235/235 [==============================] - 4430s 19s/step - loss: 0.3935 - accuracy: 0.8172 - val_loss: 0.3055 - val_accuracy: 0.8734\n",
      "Epoch 2/5\n",
      " 68/235 [=======>......................] - ETA: 49:01 - loss: 0.2269 - accuracy: 0.9108"
     ]
    }
   ],
   "source": [
    "# BERT 파인튜닝 설정 및 학습 (옵티마이저/컴파일/학습)\n",
    "from transformers import create_optimizer\n",
    "\n",
    "num_train_steps = len(train_dataset) * 5       # 전체확습 step 수(steps_per_epoch * 5(epochs))\n",
    "num_warmup_steps = int(num_train_steps * 0.1)  # warmup step 수(전체의 10%)\n",
    "\n",
    "# Transformers 권장 스케줄 포함 옵티마이저 생성\n",
    "optimizer, _ = create_optimizer(\n",
    "    init_lr = 5e-5,\n",
    "    num_train_steps = num_train_steps,        # 총 학습 step 수\n",
    "    num_warmup_steps = num_warmup_steps,      # warmup step 수\n",
    "    weight_decay_rate = 0.1                   # weight decay 비율 (가중치 감쇠: 과적합 완화)\n",
    ")\n",
    "\n",
    "# 모델 학습설정\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = model.hf_compute_loss,    # HF 제공 loss 계산 함수\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_dataset, epochs=5,\n",
    "            validation_data = test_dataset,\n",
    "            batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9201c",
   "metadata": {},
   "source": [
    "- 워밍업(warmup) 스텝이란 학습 초반에는 학습률을 바로 크게 쓰지않고, 작은 값에서 시작해서 일정 스텝동안 점진적으로 올리는 구간\n",
    "    - 스텝 * 0.1 => 전체 스텝에서 10%동안 LR를 천천히 올리는 설정\n",
    "    - 동작 과정 : num_warmup_steps 동안 LR를 0 -> init_lr로 선형으로 증가시키고, 워밍업이 끝나면 LR가 점점 감소한다.\n",
    "    - 사용 이유 : BERT 같은 사전학습 모델이 파인튜닝시에 초반에 LR가 크면 가중치가 갑자기 크게 바뀌어서 학습이 불안정/발산이 일어나 성능이 흔들릴 가능성이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8374190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 모델/토크나이저 저장\n",
    "model.save_pretrained('nsmc_model/bert-base')        # 학습된 모델 가중치/설정(config) 저장\n",
    "tokenizer.save_pretrained('nsmc_model/bert_base')    # 토크나이저 파일(vocab, tokenizer_config 등) 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32872dce",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분류 라벨 값 지정\n",
    "model.config.id2label = {\n",
    "    0: \"부정\",\n",
    "    1: \"긍정\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성분석 파이프라인 생성\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# 입력 텍스트 -> 토큰화 -> 모델 추론 -> 라벨/점수 반환 파이프라인\n",
    "sentiment_classifier = TextClassificationPipeline(\n",
    "    tokenizer = tokenizer,      # 사용할 토크나이저\n",
    "    model = model,              # 사용할 분류 모델\n",
    "    framework = 'tf',           # TensorFlow 기반 모델 사용\n",
    "    return_all_scores = True    # 모든 라벨 점수(확률/스코어) 반환\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier(\"인생 영화를 찾았습니다!!!\")  # 입력 문장에 대해 부정/긍정 점수 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7548b38",
   "metadata": {},
   "source": [
    "# HuggingFace\n",
    "\n",
    "### push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e361b1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
