{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed08bfc",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention 계산 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "724e216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x : torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# batch_size, seq_len, embedding_dim\n",
    "\n",
    "x = torch.tensor([[[1.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 2.0, 0.0, 2.0],\n",
    "                   [1.0, 1.0, 1.0, 1.0]]])\n",
    "# 배치 1, 길이 3, 차원 4\n",
    "print( '입력 x :', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7f23d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : torch.Size([1, 3, 4])\n",
      "K : torch.Size([1, 3, 4])\n",
      "V : torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Q, K, V를 생성하는 선형층\n",
    "W_q = nn.Linear(4,4,bias=False) # Query 생성용 선형 변환(4 -> 4)\n",
    "W_k = nn.Linear(4,4,bias=False) # Key 생성용 선형 변환(4 -> 4)\n",
    "W_v = nn.Linear(4,4,bias=False) # Value 생성용 선형 변환(4 -> 4)\n",
    "\n",
    "# Q, K, V\n",
    "Q = W_q(x)      # X -> Q (배치, 길이, 차원)\n",
    "K = W_k(x)      # X -> K (배치, 길이, 차원)\n",
    "V = W_v(x)      # X -> V (배치, 길이, 차원)\n",
    "\n",
    "print(\"Q :\", Q.shape)\n",
    "print(\"K :\", K.shape)\n",
    "print(\"V :\", V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd5c67e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atten_scores tensor([[[-0.1935, -0.0423, -0.2146],\n",
      "         [ 0.6141, -0.7689,  0.2296],\n",
      "         [ 0.1135, -0.4267, -0.0998]]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. Q, K, 유사도 계산\n",
    "attn_scores = torch.matmul(Q,K.transpose(-2,-1))        # Q*K^T로 토큰간 유사도(Score) 계산\n",
    "attn_scores /= Q.size(-1) ** 0.5                        # 차원(d_k)로 나눠 score 스케일 조정 (softmax 안정화)\n",
    "print(\"atten_scores\",attn_scores)                       # score 행렬 (1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c9ff47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights : tensor([[[0.3182, 0.3702, 0.3116],\n",
      "         [0.5177, 0.1299, 0.3525],\n",
      "         [0.4183, 0.2437, 0.3380]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 2. attention 분포(확률)\n",
    "attn_weights = F.softmax(attn_scores, dim=-1)            # 각 토큰이 발라볼 비율을 확룰로 변환 (행 단위 합 = 1)\n",
    "print(\"attn_weights :\", attn_weights)                    # attention 가중치 (1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f3f610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_value : torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 3. V-attention 분포의 가중합\n",
    "output = torch.matmul(attn_weights, V)\n",
    "print(\"attn_value :\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7262bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x : tensor([[[1., 0., 1., 0.],\n",
      "         [0., 2., 0., 2.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "\n",
      "Q : tensor([[[ 0.1149,  0.3946, -0.5309,  0.0528],\n",
      "         [-1.3997, -0.4482,  0.2062,  0.2142],\n",
      "         [-0.5850,  0.1705, -0.4278,  0.1599]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "K : tensor([[[-0.7800, -0.3942,  0.2269, -0.4064],\n",
      "         [ 1.3707, -0.5877,  0.0672,  0.4835],\n",
      "         [-0.0946, -0.6880,  0.2605, -0.1646]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "V : tensor([[[ 0.3892,  0.7641, -0.5828,  0.3151],\n",
      "         [ 0.8578, -0.6832,  0.6244, -1.3132],\n",
      "         [ 0.8181,  0.4225, -0.2706, -0.3415]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "attention 분포 : tensor([[[0.3182, 0.3702, 0.3116],\n",
      "         [0.5177, 0.1299, 0.3525],\n",
      "         [0.4183, 0.2437, 0.3380]]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "출력 ouptut : tensor([[[ 0.6963,  0.1219, -0.0386, -0.4923],\n",
      "         [ 0.6012,  0.4558, -0.3160, -0.1278],\n",
      "         [ 0.6483,  0.2959, -0.1830, -0.3037]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Attention 중간 결과 (Q/K/V)와 분포, 최종 출력 확인\n",
    "print('입력 x :', x)    # 원본 입력값\n",
    "print('\\nQ :', Q)       # Query 벡터 (선형변환 결과)\n",
    "print('\\nK :', K)       # Key 벡터 (선형변환 결과)\n",
    "print('\\nV :', V)       # Value 벡터 (선형변환 결과)\n",
    "\n",
    "print('\\nattention 분포 :', attn_weights)   # 가중치 : 각토큰이 다른 토큰을 얼마나 참조하는지(확률 분포)\n",
    "print('\\n출력 ouptut :', output)            # attention 가중합으로 만들어진 최종 출력 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917b78d",
   "metadata": {},
   "source": [
    "## Multi-Head Attention (헤드 분할/결합) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "486e2100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x : torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0],\n",
    "                   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]])  # 배치1, 길이3, 차원8\n",
    "print('입력 x :', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11d197f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : torch.Size([1, 3, 8])\n",
      "K : torch.Size([1, 3, 8])\n",
      "V : torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "B, T, embedding_dim = x.shape               # B, T, E\n",
    "num_head = 4                                # 헤드 개수 \n",
    "heading_dim = embedding_dim // num_head     # 헤드당 차원 (d_k)\n",
    "\n",
    "W_q = nn.Linear(embedding_dim, embedding_dim, bias = False)     # Query 생성용 선형 변환(8 -> 8)\n",
    "W_k = nn.Linear(embedding_dim, embedding_dim, bias = False)     # Key 생성용 선형 변환\n",
    "W_v = nn.Linear(embedding_dim, embedding_dim, bias = False)     # Value 생성용 선형 변환\n",
    "\n",
    "# Q, K, V\n",
    "Q = W_q(x)  # (B, T, 8) -> (B, T, 8) \n",
    "K = W_k(x)  # (B, T, 8) -> (B, T, 8) \n",
    "V = W_v(x)  # (B, T, 8) -> (B, T, 8) \n",
    "\n",
    "print(\"Q :\", Q.shape)\n",
    "print(\"K :\", K.shape)\n",
    "print(\"V :\", V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d47a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_head : torch.Size([1, 4, 3, 2])\n",
      "K_head : torch.Size([1, 4, 3, 2])\n",
      "V_head : torch.Size([1, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 헤드 분할\n",
    "# B, T, embedding_dim\n",
    "# -> B, T, num_head, heading_dim\n",
    "# -> B, num_head, T, heading_dim\n",
    "Q_head = Q.view(B, T, num_head, heading_dim).transpose(1, 2)    # Q를 헤드별로 쪼개고(num_head) 차원 위치 교환\n",
    "K_head = K.view(B, T, num_head, heading_dim).transpose(1, 2)    # K도 동일하게 헤드 분할\n",
    "V_head = V.view(B, T, num_head, heading_dim).transpose(1, 2)    # V도 동일하게 헤드 분할\n",
    "\n",
    "print(\"Q_head :\", Q_head.shape) # (B, num_head, T, heading_dim)\n",
    "print(\"K_head :\", K_head.shape) # (B, num_head, T, heading_dim)\n",
    "print(\"V_head :\", V_head.shape) # (B, num_head, T, heading_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1277d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어텐션 스코어 : torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Q, K 유사도 계산\n",
    "attn_scores = torch.matmul(Q_head, K_head.transpose(-2,-1))     # 각 헤드별로 Q*K^T 계산 (B, num_head, T, T) \n",
    "attn_scores /= embedding_dim ** 0.5                             # 스케일링 (default)\n",
    "print(\"어텐션 스코어 :\", attn_scores.shape)                     # score shape 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40dc684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# attention 분포계산\n",
    "attn_weights = F.softmax(attn_scores, dim=-1)            # 마지막 축을 기준으로 softmax -> 확률 분포\n",
    "print(\"어텐션 분포 :\", attn_weights.shape)               # (B, num_head, T, T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e111aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 어텐션값 : torch.Size([1, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# V와 가중합 계산\n",
    "output = torch.matmul(attn_weights, V_head)     # 가중합 -> (B, num_head, T, heading_dim)\n",
    "print('출력 어텐션값 :', output.shape)          # 헤드별 출력 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b93069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 (헤드결합) : torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# 헤드 결합\n",
    "output = output.transpose(1, 2)                          # (B, num_ead, T, d_k) -> (B, T, num_head,  d_k)\n",
    "output = output.contiguous().view(B, T, embedding_dim)   # (B, T, num_head,  d_k) -> (B, T, E:d_model)\n",
    "print(\"출력 (헤드결합) :\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb9fca",
   "metadata": {},
   "source": [
    "```\n",
    "tensor.contiguous() : view() 호출하기 전 메모리의 연속된 상태를 변환\n",
    "\n",
    "일반 Attention vs Multi-Head Attention\n",
    "(1) 같은 문장에서도 “관계”는 여러 종류라서\n",
    "예: “나는 어제 은행에 갔다”\n",
    "“은행”이 finance인지 river bank인지 문맥으로 판단해야 함\n",
    "어떤 헤드는 “시간/장소 단서”에\n",
    "다른 헤드는 “주변 단어 의미”에\n",
    "또 다른 헤드는 “문장 전역 정보”에 집중하는 식으로 동시에 여러 관계를 잡아냄\n",
    "\n",
    "(2) 긴 문장/복잡한 문맥에서 더 잘 버팀\n",
    "싱글 attention은 전역을 다 보긴 하지만 “한 가지 정렬”로만 보니까,\n",
    "복잡한 의존성이 많아질수록 한 번에 잡기 힘든데\n",
    "MHA는 여러 헤드가 분산해서 잡아주니 안정적.\n",
    "\n",
    "(3) 병렬 연산이 잘 맞아서(Transformer의 장점 극대화)\n",
    "RNN처럼 순차가 아니라 행렬곱 중심이라 GPU에서 효율이 좋고,\n",
    "MHA는 “여러 attention을 병렬로” 돌려도 구조적으로 잘 맞음.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
