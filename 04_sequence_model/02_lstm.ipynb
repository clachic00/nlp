{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9131e3",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "\n",
    "LSTM(Long Short-Term Memory)은 **순환신경망(RNN, Recurrent Neural Network)**의 일종으로, RNN의 단점인 **장기 의존성 문제**를 해결하기 위해 고안된 신경망 구조이다.\n",
    "\n",
    "**LSTM의 주요 특징**\n",
    "1. **장기 의존성(Long-Term Dependency) 처리**\n",
    "   - 일반적인 RNN은 시간이 길어질수록 과거의 정보를 잘 기억하지 못하는 **기울기 소멸(Gradient Vanishing)** 문제가 발생한다.\n",
    "   - LSTM은 **Cell State**와 **게이트 구조**를 통해 중요한 정보를 장기적으로 유지할 수 있다.\n",
    "\n",
    "2. **게이트(Gates) 구조**\n",
    "   - LSTM은 정보를 선택적으로 기억하거나 잊게 해주는 3가지 게이트로 구성된다:\n",
    "     - **입력 게이트(Input Gate):** 새로운 정보를 얼마나 저장할지 결정한다.\n",
    "     - **망각 게이트(Forget Gate):** 기존 정보를 얼마나 잊을지 결정한다.\n",
    "     - **출력 게이트(Output Gate):** 현재 상태를 출력에 얼마나 반영할지 결정한다.\n",
    "\n",
    "3. **Cell State**\n",
    "   - 네트워크의 **기억 장치** 역할을 하며, 중요하지 않은 정보는 제거하고 중요한 정보는 유지한다.\n",
    "\n",
    "\n",
    "**LSTM의 구조**\n",
    "\n",
    "![](https://d.pr/i/iPf2jG+)\n",
    "\n",
    "아래는 LSTM의 한 타임스텝(time step)에서 이루어지는 연산 과정이다:\n",
    "\n",
    "1. **망각 게이트 (Forget Gate)**  \n",
    "    * 이전 상태 $h_{t-1}$와 입력 $x_t$를 통해 제거할 정보를 결정한다.\n",
    "\n",
    "$$\n",
    "f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\n",
    "$$\n",
    "\n",
    "2. **입력 게이트 (Input Gate)**\n",
    "    - 입력 게이트 $i_t$와 새로운 정보 $\\tilde{C}_t$를 결합하여 Cell State에 반영할 정보를 생성한다.\n",
    "    \n",
    "$$\n",
    "i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\n",
    "$$\n",
    "\n",
    "3. **Cell State 업데이트**  \n",
    "    * 이전 Cell State $C_{t-1}$와 새로운 정보의 조합으로 현재 Cell State를 업데이트한다.\n",
    "\n",
    "$$\n",
    "C_t = f_t \\cdot C_{t-1} + i_t \\cdot \\tilde{C}_t\n",
    "$$\n",
    "\n",
    "    \n",
    "\n",
    "4. **출력 게이트 (Output Gate)**  \n",
    "    * 출력 게이트 $o_t$와 업데이트된 Cell State $C_t$를 통해 새로운 은닉 상태 $h_t$를 계산한다.\n",
    "    \n",
    "$$\n",
    "o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t = o_t \\cdot \\tanh(C_t)\n",
    "$$\n",
    "\n",
    "**LSTM의 장점**\n",
    "\n",
    "1. **장기 시퀀스 데이터 처리**: 시간의 흐름에 따라 발생하는 데이터를 잘 학습한다.\n",
    "2. **텍스트, 음성, 시계열 데이터에 적합**: 언어 모델링, 번역, 주가 예측, 음성 인식 등 다양한 분야에서 활용된다.\n",
    "3. **기울기 소멸 문제 해결**: Cell State와 게이트 구조 덕분에 학습이 안정적이다.\n",
    "\n",
    "**추가 활용**\n",
    "\n",
    "- **양방향 LSTM (Bidirectional LSTM)**: 양방향으로 데이터를 처리하여 더 많은 정보를 학습할 수 있다.\n",
    "- **Stacked LSTM**: LSTM 레이어를 여러 층 쌓아 더 복잡한 패턴을 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d13e7",
   "metadata": {},
   "source": [
    "## LSTM 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b12b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 5])\n",
      "torch.Size([1, 2, 5])\n",
      "torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "import torch                         # PyTorch(텐서 연산/딥러닝) 라이브러리 불러오기\n",
    "import torch.nn as nn                # 신경망 레이어(nn) 모듈을 nn이라는 별칭으로 불러오기\n",
    "import torch.optim as optim          # 최적화 알고리즘 (Adam 등)\n",
    "batch_size = 2                       # B : 한 번에 처리할 샘플(문장) 개수 = 2\n",
    "seq_len = 3                          # T : 시퀀스 길이(타임스텝 수) = 3\n",
    "input_size = 4                       # F : 각 타임스텝의 입력 특징(feature) 차원 = 4\n",
    "hidden_size = 5                      # H : LSTM의 hidden state(은닉 상태) 차원 = 5\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, input_size)  # (B, T, F) 모양의 랜덤 입력 텐서 생성\n",
    "print(x.shape)                       # 입력 텐서의 shape 출력\n",
    "\n",
    "# LSTM 생성 (B, T, F) 형태로 입력을 받도록 설정\n",
    "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)  # batch_first=True로 입력을 (B,T,F)로 받는 LSTM 생성\n",
    "output, (hidden, cell) = lstm(x)              # 입력 x를 LSTM에 넣어 전체 출력(output)과 마지막 hidden(hidden) 얻기\n",
    "\n",
    "print(output.shape)                  # output: 모든 타임스텝의 hidden state들 shape 출력 (B, T, H)\n",
    "print(hidden.shape)                  # hidden: 마지막 타임스텝의 hidden state shape 출력 (num_layers, B, H)\n",
    "print(cell.shape)                    # (Num_layers, B, H) : 마지막 시점 cell state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f616c1",
   "metadata": {},
   "source": [
    "## IMDB 리뷰 감성분석\n",
    "- IMDB 데이터는 영화 리뷰 텍스트와 그 리뷰의 감성(긍정/부정) 라벨로 구성된 이진 분류용 데이터셋\n",
    "- 입력(X): 영화 리뷰 문장(원문 텍스트) → `tensorflow.keras.datasets.imdb`로 불러오면 “바로 모델에 넣어 실습할 수 있게” 미리 전처리된 형태(단어→정수 ID)로 제공\n",
    "- 정답(y): 감성 라벨 0=부정, 1=긍정\n",
    "- imdb.load_data(num_words=vocab_size)의 의미: 빈도 상위 vocab_size개 단어만 단어사전에 남기고, 나머지는(덜 나온 단어) 잘리거나 OOV로 처리되는 방식\n",
    "\n",
    "- 결과적으로 **“영화 리뷰가 긍정인지 부정인지 맞추는 감성분류 데이터”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8590c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\numpy\\lib\\_format_impl.py:838: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  array = pickle.load(fp, **pickle_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "vocab_size = 300                # 사용할 단어 사전 크기 (빈도 상위인 단어만 유지)\n",
    "\n",
    "# IMDB 데이터 로드 (단어 ID 시퀀스 형태)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "print(X_train.shape, y_train.shape)     # 학습 데이터 개수\n",
    "print(X_test.shape, y_test.shape)       # 테스트 데이터 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc48b5",
   "metadata": {},
   "source": [
    "imdb 단어사전 생성 및 리뷰 디코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e938226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '[PAD]'),\n",
       " (1, '[START]'),\n",
       " (2, '[OOV]'),\n",
       " (3, 'the'),\n",
       " (4, 'and'),\n",
       " (5, 'a'),\n",
       " (6, 'of'),\n",
       " (7, 'to'),\n",
       " (8, 'is'),\n",
       " (9, 'br')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어사전 생성\n",
    "from keras.datasets import imdb                          # IMDB 데이터셋과 단어 인덱스를 제공하는 모듈\n",
    "\n",
    "word_index = imdb.get_word_index()                       # 단어 → 정수 인덱스 매핑 딕셔너리 로드\n",
    "\n",
    "pad_token = 0                                            # 패딩 토큰 인덱스\n",
    "start_char = 1                                           # 문장 시작 토큰 인덱스\n",
    "oov_char = 2                                             # 사전에 없는 단어(OOV) 토큰 인덱스\n",
    "index_from = 2                                           # 실제 단어 인덱스가 시작되는 offset 값\n",
    "\n",
    "# word_index(word->index)를 index->word 로 뒤집어서 생성\n",
    "index_word = {                                           # 정수 인덱스 → 단어 매핑 딕셔너리 생성\n",
    "    index + index_from: word                             # Keras IMDB는 index_from만큼 인덱스를 밀어서 사용\n",
    "    for word, index in word_index.items()                # (단어, 인덱스) 쌍을 순회\n",
    "    if index <= vocab_size                               # vocab_size 이하 단어만 사용\n",
    "}\n",
    "\n",
    "index_word[pad_token] = '[PAD]'                          # 0번 인덱스를 패딩 토큰으로 지정\n",
    "index_word[start_char] = '[START]'                       # 1번 인덱스를 문장 시작 토큰으로 지정\n",
    "index_word[oov_char] = '[OOV]'                           # 2번 인덱스를 미등록 단어 토큰으로 지정\n",
    "\n",
    "index_word = dict(sorted(index_word.items(), key=lambda item: item[0]))  \n",
    "# 인덱스 번호를 기준으로 정렬하여 가독성 있게 재구성\n",
    "\n",
    "list(index_word.items())[:10]                            # 앞에서부터 10개의 (인덱스, 단어) 쌍 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "530f32d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[START] that on as about [OOV] [OOV] [OOV] [OOV] really [OOV] [OOV] see [OOV] and again who each a are any about [OOV] life what [OOV] [OOV] br they [OOV] everything a though and part life look [OOV] [OOV] [OOV] like and part [OOV] [OOV] for [OOV] from this [OOV] and take what as of those [OOV] movie that on and [OOV] [OOV] [OOV] and on me because i as about [OOV] from been was this [OOV] and on for [OOV] for i as [OOV] with [OOV] a which [OOV] i is [OOV] is two a and [OOV] [OOV] as [OOV] see [OOV] by and still i as from [OOV] a are off good who scene some are [OOV] by of on i come he bad more a that [OOV] as into [OOV] is and films best [OOV] was each and [OOV] to [OOV] a [OOV] who me about [OOV] [OOV] his [OOV] [OOV] has to and [OOV] [OOV] this characters how and [OOV] was american too at [OOV] no his something of enough [OOV] with and bit on film say [OOV] his [OOV] a back one [OOV] with good who he there's made are characters and bit really as from [OOV] how i as actor a as [OOV] plot think at was as [OOV] movie quite at\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 ID 시퀀스를 텍스트 리뷰로 디코딩\n",
    "decoded_review = ' '.join(index_word.get(i, \"?\") for i in X_train[0])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7986ae0",
   "metadata": {},
   "source": [
    "정확도가 중요하면 vocab_size를 늘린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3286510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000,) (15000,)\n",
      "(10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 메모리 사용량 조절 train_size, test_size\n",
    "train_size = 15000   # 학습 샘플 수\n",
    "test_size = 10000    # 테스트 샘플 수 \n",
    "X_train = X_train[:train_size]\n",
    "y_train = y_train[:train_size]\n",
    "X_test = X_test[:test_size]\n",
    "y_test = y_test[:test_size]\n",
    "\n",
    "print(X_train.shape, y_train.shape) # 학습 데이터 개수\n",
    "print(X_test.shape, y_test.shape)   # 테스트 데이터 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65347de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1,  14,  22,  16,  43,   2,   2,   2,   2,  65,   2,   2,  66,   2,\n",
       "           4, 173,  36, 256,   5,  25, 100,  43,   2, 112,  50,   2,   2,   9,\n",
       "          35,   2, 284,   5, 150,   4, 172, 112, 167,   2,   2,   2,  39,   4,\n",
       "         172,   2,   2,  17,   2,  38,  13,   2,   4, 192,  50,  16,   6, 147,\n",
       "           2,  19,  14,  22,   4,   2,   2,   2,   4,  22,  71,  87,  12,  16,\n",
       "          43,   2,  38,  76,  15,  13,   2,   4,  22,  17,   2,  17,  12,  16,\n",
       "           2,  18,   2,   5,  62,   2,  12,   8,   2,   8, 106,   5,   4,   2,\n",
       "           2,  16,   2,  66,   2,  33,   4, 130,  12,  16,  38,   2,   5,  25,\n",
       "         124,  51,  36, 135,  48,  25,   2,  33,   6,  22,  12, 215,  28,  77,\n",
       "          52,   5,  14,   2,  16,  82,   2,   8,   4, 107, 117,   2,  15, 256,\n",
       "           4,   2,   7,   2,   5,   2,  36,  71,  43,   2,   2,  26,   2,   2,\n",
       "          46,   7,   4,   2,   2,  13, 104,  88,   4,   2,  15, 297,  98,  32,\n",
       "           2,  56,  26, 141,   6, 194,   2,  18,   4, 226,  22,  21, 134,   2,\n",
       "          26,   2,   5, 144,  30,   2,  18,  51,  36,  28, 224,  92,  25, 104,\n",
       "           4, 226,  65,  16,  38,   2,  88,  12,  16, 283,   5,  16,   2, 113,\n",
       "         103,  32,  15,  16,   2,  19, 178,  32]),\n",
       " torch.Size([218]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB 시퀀스/라벨을 PyTorch Tensor로 변환\n",
    "X_train = [torch.tensor(seq, dtype = torch.long) for seq in X_train]    # 학습 시퀀스(단어 ID 리스트) -> LongTensor 로 변환\n",
    "X_test = [torch.tensor(seq, dtype = torch.long) for seq in X_test]      # 테스트 시퀀스(단어 ID 리스트) -> LongTensor 로 변환\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype = torch.float)    # 학습 라벨(0/1) -> FloatTensor로 변환\n",
    "y_test = torch.tensor(y_test, dtype = torch.float)      # 테스트 라벨(0/1) -> FloatTensor로 변환\n",
    "\n",
    "X_train[0] , X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09803ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15000, 100]), torch.Size([10000, 100]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시퀀스 패딩 처리로 길이 고정\n",
    "import torch.nn.functional as F    # padding 등 텐서 연산을 위한 PyTorch 함수 모듈\n",
    "\n",
    "seq_len = 100                     # 모든 시퀀스를 맞출 목표 길이(최대 길이)\n",
    "\n",
    "# 시퀀스들을 max_len 길이로 패딩(0) 또는 자르기하여 텐서로 변환\n",
    "def pad_sequences(sequences, max_len):   # 시퀀스 리스트와 최대 길이를 입력으로 받는 함수\n",
    "    padded_sequences = []                # 패딩된 시퀀스를 저장할 리스트\n",
    "    for seq in sequences:                # 각 시퀀스에 대해 반복\n",
    "        if len(seq) < max_len:            # 시퀀스 길이가 max_len보다 짧으면\n",
    "            padded_seq = F.pad(seq, (0, max_len - len(seq)), value=0)  # 뒤쪽에 0으로 패딩\n",
    "        else:                             # 시퀀스 길이가 max_len 이상이면\n",
    "            padded_seq = seq[:max_len]    # max_len 길이만큼 자르기\n",
    "        \n",
    "        padded_sequences.append(padded_seq)  # 처리된 시퀀스를 리스트에 추가\n",
    "    return torch.stack(padded_sequences)     # 리스트를 하나의 텐서로 변환하여 반환\n",
    "\n",
    "X_train_padded = pad_sequences(X_train, seq_len)  # 학습 데이터 시퀀스를 길이 100으로 패딩\n",
    "X_test_padded = pad_sequences(X_test, seq_len)    # 테스트 데이터 시퀀스를 길이 100으로 패딩\n",
    "\n",
    "X_train_padded.shape, X_test_padded.shape          # 패딩된 학습/테스트 텐서의 shape 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "355fc3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15000, 100, 300]), torch.Size([10000, 100, 300]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원-핫 인코딩으로 단어 ID를 벡터로 변환\n",
    "X_train_onehot = F.one_hot(X_train_padded, num_classes=vocab_size)  # (N, seq_len) ID -> (N, seq_len, vocab_size) 원-핫\n",
    "X_test_onehot = F.one_hot(X_test_padded, num_classes=vocab_size)    # 테스트 데이터 동일\n",
    "\n",
    "X_train_onehot.shape, X_test_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa63c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (lstm): LSTM(300, 16, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB 감성분류 LSTM 모델\n",
    "class SentimentNet(nn.Module):                 # PyTorch nn.Module을 상속받은 LSTM 모델 클래스 정의\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):  # 입력·은닉·출력 차원을 받는 생성자\n",
    "        super().__init__()                          # 부모 클래스(nn.Module) 초기화\n",
    "        self.lstm = nn.LSTM(                          # LSTM 레이어 정의\n",
    "            input_size=input_dim,                   # 각 타임스텝 입력 벡터 차원\n",
    "            hidden_size=hidden_dim,                  # 은닉 상태 차원\n",
    "            batch_first=True                        # 입력 형태를 (B, T, F)로 사용\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # 마지막 hidden을 출력 차원으로 변환하는 선형 레이어\n",
    "    \n",
    "    def forward(self, x):                           # 순전파 정의\n",
    "        output, (hidden, cell) = self.lstm(x)       # output : (B,T,H), hidden / cell : (1:layers_num, B, H)\n",
    "        output = self.fc(hidden[-1])                # 마지막 레이어 hidden -> (B, H) -> fc 적용\n",
    "        return output                               # 최종 예측 결과 반환 (B, output_dim) 반환\n",
    "    \n",
    "input_dim = vocab_size                              # 단어 집합 크기(입력 차원)\n",
    "hidden_dim = 16                                     # LSTM 은닉 상태 차원\n",
    "output_dim = 1                                      # 이진 분류를 출력(logit 1개)\n",
    "\n",
    "model = SentimentNet(input_dim, hidden_dim, output_dim)  # 모델 생성\n",
    "model                                             # 모델 구조 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0c016fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0 torch.Size([64, 300])\n",
      "lstm.weight_hh_l0 torch.Size([64, 16])\n",
      "lstm.bias_ih_l0 torch.Size([64])\n",
      "lstm.bias_hh_l0 torch.Size([64])\n",
      "fc.weight torch.Size([1, 16])\n",
      "fc.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 파라미터(가중치/편향) 이름과 Shape확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e270e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SentimentNet                             --\n",
       "├─LSTM: 1-1                              20,352\n",
       "├─Linear: 1-2                            17\n",
       "=================================================================\n",
       "Total params: 20,369\n",
       "Trainable params: 20,369\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchinfo로 모델 요약(summary) 확인\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model)  # 모델 레이어별 shape/파라미터 수 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43543527",
   "metadata": {},
   "source": [
    "fc는 보통 Fully Connected Layer(전결합층)\n",
    "- self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    - LSTM에서 마지막 은닉벡터(크기 hidden_dim)을 최정 출력 차원(output_dim)으로 바꿔주는 선형층\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20f9a4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15000, 1]), torch.Size([10000, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 출력 라벨을 2차원 텐서로 변환\n",
    "y_train = y_train.unsqueeze(1)  # (N,) -> (N,1)로 차원 추가\n",
    "y_test = y_test.unsqueeze(1)    # (N,) -> (N,1)로 차원 추가\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa37630",
   "metadata": {},
   "source": [
    "모델 출력이 (N,1) 형태라서 라벨도 (N,1)로 맞춰 손실계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34465316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 데이터 분리 및 DataLoader 구성\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset  # 데이터셋 분리/로딩에 필요한 PyTorch 도구들\n",
    "\n",
    "batch_size = 64                                  # 한 번에 모델에 넣을 데이터 개수(미니배치 크기)\n",
    "\n",
    "train_size = int(len(X_train_onehot) * 0.8)      # 전체 학습 데이터의 80%를 train으로 사용\n",
    "val_size = len(X_train_onehot) - train_size      # 나머지 20%를 validation 데이터로 사용\n",
    "\n",
    "# TensorDataset:\n",
    "#   입력(X)과 정답(y)을 하나의 묶음 데이터셋으로 만들어줌\n",
    "#   -> (X[i], y[i]) 형태로 반환됨\n",
    "dataset = TensorDataset(X_train_onehot, y_train) # (입력, 라벨) 쌍으로 이루어진 Dataset 생성\n",
    "\n",
    "# random_split:\n",
    "#   하나의 Dataset을 train/validation용으로 랜덤하게 분리\n",
    "#   -> 데이터 누수 방지를 위해 보통 학습 전에 1회만 수행\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset,                                    # 분리할 전체 데이터셋\n",
    "    [train_size, val_size]                     # 분리 비율 (train, validation)\n",
    ")\n",
    "\n",
    "\n",
    "# DataLoader:\n",
    "#   Dataset에서 데이터를 미니배치 단위로 꺼내주는 도구\n",
    "#   학습 루프에서 for문으로 사용 가능\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,                              # 학습용 데이터셋\n",
    "    batch_size=batch_size,                      # 미니배치 크기\n",
    "    shuffle=True                                # 매 epoch마다 데이터 순서를 섞음 (학습 성능 향상)\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,                                # 검증용 데이터셋\n",
    "    batch_size=batch_size,                      # 미니배치 크기\n",
    "    shuffle=False                               # 검증 데이터는 순서 고정 (재현성)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7f356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<04:27,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100 : Train Lost 0.6945 Train Acc 0.4961 val_loss 0.6936 val_acc 0.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:08<07:24,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 100 : Train Lost 0.6937 Train Acc 0.4938 val_loss 0.6932 val_acc 0.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:20<12:31,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 100 : Train Lost 0.6933 Train Acc 0.5011 val_loss 0.6929 val_acc 0.4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:22<09:01,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 100 : Train Lost 0.6930 Train Acc 0.5113 val_loss 0.6927 val_acc 0.5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:24<07:05,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 100 : Train Lost 0.6927 Train Acc 0.5210 val_loss 0.6926 val_acc 0.5253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:27<05:57,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 100 : Train Lost 0.6925 Train Acc 0.5220 val_loss 0.6924 val_acc 0.5220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:30<05:18,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 100 : Train Lost 0.6923 Train Acc 0.5241 val_loss 0.6922 val_acc 0.5233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:32<04:46,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 100 : Train Lost 0.6921 Train Acc 0.5255 val_loss 0.6920 val_acc 0.5283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:35<04:31,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 100 : Train Lost 0.6918 Train Acc 0.5280 val_loss 0.6918 val_acc 0.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:38<04:32,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 100 : Train Lost 0.6916 Train Acc 0.5267 val_loss 0.6916 val_acc 0.5313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:47<07:24,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 100 : Train Lost 0.6914 Train Acc 0.5377 val_loss 0.6914 val_acc 0.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:58<10:02,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 100 : Train Lost 0.6910 Train Acc 0.5423 val_loss 0.6911 val_acc 0.5327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:11<12:31,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / 100 : Train Lost 0.6907 Train Acc 0.5430 val_loss 0.6909 val_acc 0.5367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:24<14:13,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 100 : Train Lost 0.6904 Train Acc 0.5503 val_loss 0.6905 val_acc 0.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [01:33<13:46,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 / 100 : Train Lost 0.6900 Train Acc 0.5517 val_loss 0.6902 val_acc 0.5473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:36<10:28,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 / 100 : Train Lost 0.6894 Train Acc 0.5550 val_loss 0.6897 val_acc 0.5480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:38<08:10,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 / 100 : Train Lost 0.6888 Train Acc 0.5623 val_loss 0.6889 val_acc 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:40<06:33,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 100 : Train Lost 0.6876 Train Acc 0.5733 val_loss 0.6874 val_acc 0.5580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:42<05:25,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 / 100 : Train Lost 0.6765 Train Acc 0.5954 val_loss 0.6592 val_acc 0.6313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:45<04:41,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 / 100 : Train Lost 0.6540 Train Acc 0.6412 val_loss 0.6527 val_acc 0.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:47<04:15,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 100 : Train Lost 0.6443 Train Acc 0.6534 val_loss 0.6411 val_acc 0.6580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:50<04:01,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 / 100 : Train Lost 0.6332 Train Acc 0.6688 val_loss 0.6431 val_acc 0.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:53<03:50,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 / 100 : Train Lost 0.6255 Train Acc 0.6791 val_loss 0.6317 val_acc 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:55<03:42,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 100 : Train Lost 0.6204 Train Acc 0.6869 val_loss 0.6277 val_acc 0.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:58<03:40,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 100 : Train Lost 0.6114 Train Acc 0.6967 val_loss 0.6233 val_acc 0.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [02:02<03:42,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 / 100 : Train Lost 0.6063 Train Acc 0.6968 val_loss 0.6200 val_acc 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [02:05<03:40,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 / 100 : Train Lost 0.6010 Train Acc 0.7030 val_loss 0.6164 val_acc 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [02:07<03:29,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 100 : Train Lost 0.5951 Train Acc 0.7078 val_loss 0.6151 val_acc 0.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [02:10<03:31,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 / 100 : Train Lost 0.5915 Train Acc 0.7095 val_loss 0.6109 val_acc 0.6833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [02:13<03:22,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 / 100 : Train Lost 0.5870 Train Acc 0.7116 val_loss 0.6107 val_acc 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:16<03:18,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 100 : Train Lost 0.5830 Train Acc 0.7131 val_loss 0.6037 val_acc 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:19<03:18,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 / 100 : Train Lost 0.5787 Train Acc 0.7162 val_loss 0.6027 val_acc 0.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:22<03:23,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 / 100 : Train Lost 0.5747 Train Acc 0.7198 val_loss 0.5991 val_acc 0.6843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:26<03:42,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 / 100 : Train Lost 0.5712 Train Acc 0.7203 val_loss 0.5956 val_acc 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:29<03:27,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 100 : Train Lost 0.5680 Train Acc 0.7232 val_loss 0.5934 val_acc 0.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:32<03:17,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 / 100 : Train Lost 0.5654 Train Acc 0.7212 val_loss 0.5957 val_acc 0.6960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:35<03:11,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 / 100 : Train Lost 0.5607 Train Acc 0.7261 val_loss 0.5864 val_acc 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:38<03:06,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 100 : Train Lost 0.5575 Train Acc 0.7269 val_loss 0.5838 val_acc 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [02:41<02:59,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 / 100 : Train Lost 0.5548 Train Acc 0.7302 val_loss 0.5889 val_acc 0.6860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [02:44<02:54,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 / 100 : Train Lost 0.5534 Train Acc 0.7328 val_loss 0.5822 val_acc 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [02:46<02:52,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 100 : Train Lost 0.5488 Train Acc 0.7324 val_loss 0.5787 val_acc 0.6997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [02:49<02:46,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 100 : Train Lost 0.5479 Train Acc 0.7349 val_loss 0.5755 val_acc 0.7050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [02:52<02:44,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 / 100 : Train Lost 0.5452 Train Acc 0.7369 val_loss 0.5805 val_acc 0.7057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [02:55<02:39,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 / 100 : Train Lost 0.5410 Train Acc 0.7387 val_loss 0.5715 val_acc 0.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [02:58<02:34,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 100 : Train Lost 0.5384 Train Acc 0.7412 val_loss 0.5704 val_acc 0.7020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [03:00<02:32,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 / 100 : Train Lost 0.5372 Train Acc 0.7413 val_loss 0.5717 val_acc 0.7023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [03:03<02:28,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 / 100 : Train Lost 0.5350 Train Acc 0.7402 val_loss 0.5691 val_acc 0.7053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [03:06<02:23,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 100 : Train Lost 0.5316 Train Acc 0.7439 val_loss 0.5641 val_acc 0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [03:09<02:20,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 / 100 : Train Lost 0.5301 Train Acc 0.7457 val_loss 0.5684 val_acc 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [03:11<02:17,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 / 100 : Train Lost 0.5277 Train Acc 0.7458 val_loss 0.5667 val_acc 0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [03:14<02:14,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 100 : Train Lost 0.5258 Train Acc 0.7467 val_loss 0.5643 val_acc 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [03:17<02:11,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 / 100 : Train Lost 0.5236 Train Acc 0.7486 val_loss 0.5624 val_acc 0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [03:20<02:08,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 / 100 : Train Lost 0.5217 Train Acc 0.7502 val_loss 0.5575 val_acc 0.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [03:22<02:05,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 / 100 : Train Lost 0.5200 Train Acc 0.7495 val_loss 0.5620 val_acc 0.7140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [03:25<02:02,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 100 : Train Lost 0.5182 Train Acc 0.7544 val_loss 0.5584 val_acc 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [03:28<02:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 / 100 : Train Lost 0.5182 Train Acc 0.7522 val_loss 0.5596 val_acc 0.7133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [03:30<01:57,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 / 100 : Train Lost 0.5159 Train Acc 0.7522 val_loss 0.5605 val_acc 0.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [03:33<01:54,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 100 : Train Lost 0.5143 Train Acc 0.7531 val_loss 0.5634 val_acc 0.7140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [03:36<01:51,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 / 100 : Train Lost 0.5138 Train Acc 0.7538 val_loss 0.5616 val_acc 0.7140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [03:39<01:49,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 / 100 : Train Lost 0.5130 Train Acc 0.7529 val_loss 0.5584 val_acc 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [03:41<01:47,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 / 100 : Train Lost 0.5116 Train Acc 0.7548 val_loss 0.5603 val_acc 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [03:44<01:45,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 100 : Train Lost 0.5111 Train Acc 0.7550 val_loss 0.5564 val_acc 0.7203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [03:47<01:44,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 / 100 : Train Lost 0.5092 Train Acc 0.7569 val_loss 0.5512 val_acc 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [03:50<01:43,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 / 100 : Train Lost 0.5100 Train Acc 0.7566 val_loss 0.5544 val_acc 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [03:54<01:51,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 100 : Train Lost 0.5073 Train Acc 0.7556 val_loss 0.5562 val_acc 0.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [03:57<01:48,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 / 100 : Train Lost 0.5070 Train Acc 0.7578 val_loss 0.5562 val_acc 0.7203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [04:00<01:44,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 / 100 : Train Lost 0.5063 Train Acc 0.7576 val_loss 0.5523 val_acc 0.7180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [04:04<02:00,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 100 : Train Lost 0.5047 Train Acc 0.7607 val_loss 0.5515 val_acc 0.7143\n",
      "Early stopped at Epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# GPU 활용 가능시 GPU 기반으로 LSTM 학습 루프 (BCEWithLogits + Adam + Early Stopping)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "\n",
    "# 매모리 캐시 정리\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()          # 이진분류 손실 (시그모이드 포함 logit 입력용)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# 시각화를 위한 loss 기록\n",
    "train_losses, val_losses, train_accs, val_accs = [], [] ,[], []\n",
    "\n",
    "# 조기종료 관련\n",
    "early_stopping_patience = 20\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    total_loss, correct, total = 0, 0, 0        # 누적 손실, 정답, 전체 샘플 수\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()                   # 이전 배치 기울기 초기화\n",
    "        output = model(inputs)                  # 순전파\n",
    "        loss = criterion(output, labels)        # 손실계산\n",
    "        loss.backward()                         # 역전파\n",
    "        optimizer.step()                        # 파라미터 업데이트\n",
    "\n",
    "        # 배치 로그\n",
    "        total_loss += loss.item()               # 배치 손실을 스칼라로 누적\n",
    "        p = torch.sigmoid(output)               # logit-> 0~1 확률로 변환\n",
    "        pred = (p >= 0.5).float()   \n",
    "        correct += (pred == labels).sum().item()        # 맞춘 개수\n",
    "        total += labels.size(0)                 # 배치 샘플 수\n",
    "\n",
    "    # 에폭 로그\n",
    "    train_loss = total_loss / len(train_dataloader)     # 에폭별 평균 학습 손실\n",
    "    train_losses.append(train_loss)     \n",
    "    train_acc = correct / total\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # 검증\n",
    "    model.eval()                                # 평가모드 (Dropout, BN 비활성화)\n",
    "    val_loss, val_correct, val_total = 0, 0, 0  # 누적 손실, 정답, 전체 샘플 수\n",
    "    with torch.no_grad():                       # 기울기 계산 비활성화\n",
    "        for val_inputs, val_labels in val_dataloader:\n",
    "            val_inputs, val_labels = val_inputs.to(device).float(), val_labels.to(device).float()\n",
    "\n",
    "            output = model(val_inputs)\n",
    "            loss = criterion(output, val_labels)\n",
    "\n",
    "                    # 배치 로그\n",
    "            val_loss += loss.item()\n",
    "            p = torch.sigmoid(output)\n",
    "            pred = (p >= 0.5).float()\n",
    "            val_correct += (pred == val_labels).sum().item()\n",
    "            val_total += val_labels.size(0)\n",
    "\n",
    "        # 에폭 로그\n",
    "        val_loss = val_loss / len(val_dataloader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # 에폭 로그 출력\n",
    "        print(f'Epoch {epoch+1} / {epochs} : Train Loss {train_loss:.4f} Train Acc {train_acc:.4f} val_loss {val_loss:.4f} val_acc {val_acc:.4f}')\n",
    "\n",
    "        # 조기 종료\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter > early_stopping_patience:\n",
    "                print(f'Early stopped at Epoch {epoch + 1}')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3549ab80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses,\n",
    "    'train_acc': train_accs,\n",
    "    'val_acc': val_accs\n",
    "})\n",
    "\n",
    "df.plot() # DataFrame 컬럼들을 한번에 라인 플롯으로 시각화\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f01fc",
   "metadata": {},
   "source": [
    "### Embedding + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1811edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentEmbeddingNet(\n",
       "  (embedding): Embedding(300, 50, padding_idx=0)\n",
       "  (lstm): LSTM(50, 16, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB 감성분류 LSTM 모델 : 단어 ID 시퀀스를 Embedding 으로 변환한 뒤 LSTM을 거쳐 감성 점수 (logit)을 출력하는 모델\n",
    "class SentimentEmbeddingNet(nn.Module):                 # PyTorch nn.Module을 상속받은 LSTM 모델 클래스 정의\n",
    "    def __init__(self, input_dim,embedding_dim, hidden_dim, output_dim, num_layers=2):  # 입력·은닉·출력 차원을 받는 생성자\n",
    "        super().__init__()                          # 부모 클래스(nn.Module) 초기화\n",
    "        \n",
    "        \n",
    "        self.embedding = nn.Embedding(              # 단어 ID -> 임베딩 벡터로 변환\n",
    "           num_embeddings=vocab_size,               # 단어 사전 크기\n",
    "           embedding_dim=embedding_dim,             # 임베딩 차원 (각 차원을 embedding_dim 벡터로 표현)\n",
    "           padding_idx=0                            # PAD(0) 토큰 임베딩은 업데이트 하지 않는다.\n",
    "        )\n",
    "                \n",
    "        self.lstm = nn.LSTM(                        # LSTM 레이어 정의\n",
    "            input_size=embedding_dim,               # 각 타임스텝 입력 벡터 차원\n",
    "            hidden_size=hidden_dim,                 # 은닉 상태 차원\n",
    "            batch_first=True,                       # 입력 형태를 (B, T, F)로 사용\n",
    "            num_layers = num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # 마지막 hidden을 출력 차원으로 변환하는 선형 레이어\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)          # (B,T) -> (B,T,E)\n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        output = self.fc(hidden[-1])\n",
    "        return output\n",
    "    \n",
    "embedding_dim = 50                                  # 임베딩 벡터 차원\n",
    "hidden_dim = 16                                     # LSTM 은닉 상태 차원\n",
    "output_dim = 1                                      # 이진 분류를 출력(logit 1개)\n",
    "\n",
    "model = SentimentEmbeddingNet(vocab_size, embedding_dim, hidden_dim, output_dim)  # 모델 생성\n",
    "model                                             # 모델 구조 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "582f5ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight torch.Size([300, 50])\n",
      "lstm.weight_ih_l0 torch.Size([64, 50])\n",
      "lstm.weight_hh_l0 torch.Size([64, 16])\n",
      "lstm.bias_ih_l0 torch.Size([64])\n",
      "lstm.bias_hh_l0 torch.Size([64])\n",
      "lstm.weight_ih_l1 torch.Size([64, 16])\n",
      "lstm.weight_hh_l1 torch.Size([64, 16])\n",
      "lstm.bias_ih_l1 torch.Size([64])\n",
      "lstm.bias_hh_l1 torch.Size([64])\n",
      "fc.weight torch.Size([1, 16])\n",
      "fc.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 파라미터(가중치/편향) 이름과 Shape확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b9c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SentimentEmbeddingNet                    --\n",
       "├─Embedding: 1-1                         15,000\n",
       "├─LSTM: 1-2                              6,528\n",
       "├─Linear: 1-3                            17\n",
       "=================================================================\n",
       "Total params: 21,545\n",
       "Trainable params: 21,545\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchinfo로 모델 요약(summary) 확인\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model)  # 모델 레이어별 shape/파라미터 수 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d7589",
   "metadata": {},
   "source": [
    "파라미터 수에 따른 학습시간 계산에 사용한다. (x 데이터량)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534348ad",
   "metadata": {},
   "source": [
    "### Emebedding + LSTM(bidirectional)\n",
    "\n",
    "![](https://d.pr/i/0u69xz+)\n",
    "\n",
    "\n",
    "**Bidirectional LSTM**은 LSTM의 변형 모델로, **양방향으로 데이터를 처리**할 수 있도록 설계된 구조이다. 일반 LSTM이 입력 데이터를 **순방향(forward)**으로만 처리하는 반면, Bidirectional LSTM은 **순방향**과 **역방향(backward)**으로 데이터를 동시에 처리하여 더 많은 정보를 학습한다.\n",
    "\n",
    "\n",
    "1. **양방향 정보 학습**  \n",
    "   - 순방향 LSTM은 이전 시점의 정보만을 사용하여 다음 시점의 출력을 계산한다.\n",
    "   - Bidirectional LSTM은 데이터의 시간적 흐름을 순방향과 역방향으로 모두 고려하여 **이전**과 **이후**의 정보를 동시에 학습한다.\n",
    "\n",
    "2. **문맥 정보 강화**  \n",
    "   - 예를 들어, 텍스트 데이터를 처리할 때 문장의 맥락(Context)을 양방향으로 학습하여 더 정확한 결과를 얻을 수 있다.  \n",
    "    - 예: \"He went to the bank ...\"에서 \"bank\"가 \"은행\"인지 \"강둑\"인지 구분하기 위해 이후 단어의 정보를 활용할 수 있다.\n",
    "    - Forward LSTM:\n",
    "    ```He → went → to → the → bank → to → withdraw → money```\n",
    "    - Backward LSTM:\n",
    "    ```money → withdraw → to → bank → the → to → went → He```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a4af26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 10])\n",
      "torch.Size([4, 2, 5])\n",
      "torch.Size([4, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "import torch                         # PyTorch(텐서 연산/딥러닝) 라이브러리 불러오기\n",
    "import torch.nn as nn                # 신경망 레이어(nn) 모듈을 nn이라는 별칭으로 불러오기\n",
    "import torch.optim as optim          # 최적화 알고리즘 (Adam 등)\n",
    "batch_size = 2                       # B : 한 번에 처리할 샘플(문장) 개수 = 2\n",
    "seq_len = 3                          # T : 시퀀스 길이(타임스텝 수) = 3\n",
    "input_size = 4                       # F : 각 타임스텝의 입력 특징(feature) 차원 = 4\n",
    "hidden_size = 5                      # H : LSTM의 hidden state(은닉 상태) 차원 = 5\n",
    "num_layers = 2\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, input_size)  # (B, T, F) 모양의 랜덤 입력 텐서 생성\n",
    "print(x.shape)                       # 입력 텐서의 shape 출력\n",
    "\n",
    "# LSTM 생성 (B, T, F) 형태로 입력을 받도록 설정\n",
    "lstm = nn.LSTM(\n",
    "    input_size              # 입력 feature 차원 F : 각 시점에 들어오는 벡터 크기\n",
    "    , hidden_size           # 은닉 상태 차원 H : LSTM\n",
    "    , batch_first=True\n",
    "    , num_layers=num_layers\n",
    "    , bidirectional=True\n",
    ")  # 양방향 LSTM\n",
    "output, (hidden, cell) = lstm(x)              # 입력 x를 LSTM에 넣어 전체 출력(output)과 마지막 hidden(hidden) 얻기\n",
    "\n",
    "print(output.shape)                  # output: 모든 타임스텝의 hidden state들 shape 출력 (B, T, H)\n",
    "print(hidden.shape)                  # hidden: 마지막 타임스텝의 hidden state shape 출력 (num_layers*2, B, H)\n",
    "print(cell.shape)                    # (Num_layers*2, B, H) : 마지막 시점 cell state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fcec7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(300, 50, padding_idx=0)\n",
       "  (lstm): LSTM(50, 16, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB 감성분류 LSTM 모델 (2-layer LSTM)\n",
    "class SentimentNet(nn.Module):                 # PyTorch nn.Module을 상속받은 LSTM 모델 클래스 정의\n",
    "    def __init__(self, vocab_size, embedding_dim,hidden_dim, output_dim,num_layers=2):  # 입력·은닉·출력 차원을 받는 생성자\n",
    "        super().__init__()                          # 부모 클래스(nn.Module) 초기화\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=0\n",
    "\n",
    "        )\n",
    "        self.lstm = nn.LSTM(                          # LSTM 레이어 정의\n",
    "            input_size=embedding_dim,                   # 각 타임스텝 입력 벡터 차원\n",
    "            hidden_size=hidden_dim,                  # 은닉 상태 차원\n",
    "            batch_first=True,                        # 입력 형태를 (B, T, F)로 사용\n",
    "            bidirectional=True,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim) # 마지막 hidden을 출력 차원으로 변환하는 선형 레이어\n",
    "    \n",
    "    def forward(self, x):                           # 순전파 정의\n",
    "        x=self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)       # output : (B,T,H), hidden / cell : (1:layers_num, B, H)\n",
    "        forward_pass = hidden[-2]\n",
    "        backward_pass = hidden[-1]\n",
    "        hidden = torch.cat((forward_pass,backward_pass),dim=1)\n",
    "        output = self.fc(hidden)\n",
    "        return output                               # 최종 예측 결과 반환 (B, output_dim) 반환\n",
    "    \n",
    "embedding_dim = 50                          # 단어 집합 크기(입력 차원)\n",
    "hidden_dim = 16                                     # LSTM 은닉 상태 차원\n",
    "output_dim = 1                                      # 이진 분류를 출력(logit 1개)\n",
    "\n",
    "model = SentimentNet(vocab_size,embedding_dim, hidden_dim, output_dim, num_layers=2)  # 모델 생성\n",
    "model                                             # 모델 구조 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "278a5b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight torch.Size([300, 50])\n",
      "lstm.weight_ih_l0 torch.Size([64, 50])\n",
      "lstm.weight_hh_l0 torch.Size([64, 16])\n",
      "lstm.bias_ih_l0 torch.Size([64])\n",
      "lstm.bias_hh_l0 torch.Size([64])\n",
      "lstm.weight_ih_l0_reverse torch.Size([64, 50])\n",
      "lstm.weight_hh_l0_reverse torch.Size([64, 16])\n",
      "lstm.bias_ih_l0_reverse torch.Size([64])\n",
      "lstm.bias_hh_l0_reverse torch.Size([64])\n",
      "lstm.weight_ih_l1 torch.Size([64, 32])\n",
      "lstm.weight_hh_l1 torch.Size([64, 16])\n",
      "lstm.bias_ih_l1 torch.Size([64])\n",
      "lstm.bias_hh_l1 torch.Size([64])\n",
      "lstm.weight_ih_l1_reverse torch.Size([64, 32])\n",
      "lstm.weight_hh_l1_reverse torch.Size([64, 16])\n",
      "lstm.bias_ih_l1_reverse torch.Size([64])\n",
      "lstm.bias_hh_l1_reverse torch.Size([64])\n",
      "fc.weight torch.Size([1, 32])\n",
      "fc.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 파라미터(가중치/편향) 이름과 Shape확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a222a7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SentimentNet                             --\n",
       "├─Embedding: 1-1                         15,000\n",
       "├─LSTM: 1-2                              15,104\n",
       "├─Linear: 1-3                            33\n",
       "=================================================================\n",
       "Total params: 30,137\n",
       "Trainable params: 30,137\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchinfo로 모델 요약(summary) 확인\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model)  # 모델 레이어별 shape/파라미터 수 요약 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c2927e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 데이터 분리 및 DataLoader 구성\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset  # 데이터셋 분리/로딩에 필요한 PyTorch 도구들\n",
    "\n",
    "batch_size = 64                                  # 한 번에 모델에 넣을 데이터 개수(미니배치 크기)\n",
    "\n",
    "train_size = int(len(X_train_padded) * 0.8)      # 전체 학습 데이터의 80%를 train으로 사용\n",
    "val_size = len(X_train_padded) - train_size      # 나머지 20%를 validation 데이터로 사용\n",
    "\n",
    "dataset = TensorDataset(X_train_padded, y_train) # (입력, 라벨) 쌍으로 이루어진 Dataset 생성\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset,                                    # 분리할 전체 데이터셋\n",
    "    [train_size, val_size]                     # 분리 비율 (train, validation)\n",
    ")\n",
    "test_dataset = TensorDataset(X_test_padded, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,                              # 학습용 데이터셋\n",
    "    batch_size=batch_size,                      # 미니배치 크기\n",
    "    shuffle=True                                # 매 epoch마다 데이터 순서를 섞음 (학습 성능 향상)\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,                                # 검증용 데이터셋\n",
    "    batch_size=batch_size,                      # 미니배치 크기\n",
    "    shuffle=False                               # 검증 데이터는 순서 고정 (재현성)\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,                                # 검증용 데이터셋\n",
    "    batch_size=batch_size,                      # 미니배치 크기\n",
    "    shuffle=False                               # 검증 데이터는 순서 고정 (재현성)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:03<05:21,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100 : Train Lost 0.6924 Train Acc 0.5111 val_loss 0.6923 val_acc 0.5180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:06<05:12,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 100 : Train Lost 0.6916 Train Acc 0.5299 val_loss 0.6917 val_acc 0.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:09<05:08,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 100 : Train Lost 0.6901 Train Acc 0.5354 val_loss 0.6894 val_acc 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:12<05:04,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 100 : Train Lost 0.6866 Train Acc 0.5632 val_loss 0.6847 val_acc 0.5637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:16<05:09,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 100 : Train Lost 0.6786 Train Acc 0.5792 val_loss 0.6725 val_acc 0.5910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:42<17:20, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 100 : Train Lost 0.6677 Train Acc 0.5978 val_loss 0.6628 val_acc 0.6050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:16<28:54, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 100 : Train Lost 0.6585 Train Acc 0.6192 val_loss 0.6551 val_acc 0.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:38<30:18, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 100 : Train Lost 0.6507 Train Acc 0.6285 val_loss 0.6515 val_acc 0.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:41<22:05, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 100 : Train Lost 0.6432 Train Acc 0.6376 val_loss 0.6448 val_acc 0.6313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [01:45<16:36, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 100 : Train Lost 0.6389 Train Acc 0.6433 val_loss 0.6400 val_acc 0.6340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [01:48<12:53,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 100 : Train Lost 0.6281 Train Acc 0.6592 val_loss 0.6305 val_acc 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [01:51<10:25,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 100 : Train Lost 0.6206 Train Acc 0.6642 val_loss 0.6231 val_acc 0.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:56<09:03,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / 100 : Train Lost 0.6110 Train Acc 0.6743 val_loss 0.6152 val_acc 0.6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [02:00<08:04,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 100 : Train Lost 0.6030 Train Acc 0.6807 val_loss 0.6084 val_acc 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [02:04<07:18,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 / 100 : Train Lost 0.5943 Train Acc 0.6879 val_loss 0.6020 val_acc 0.6770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [02:08<06:50,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 / 100 : Train Lost 0.5912 Train Acc 0.6913 val_loss 0.5997 val_acc 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [02:13<06:50,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 / 100 : Train Lost 0.5855 Train Acc 0.6959 val_loss 0.5947 val_acc 0.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [02:18<06:34,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 100 : Train Lost 0.5792 Train Acc 0.7042 val_loss 0.5910 val_acc 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [02:25<07:24,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 / 100 : Train Lost 0.5742 Train Acc 0.7047 val_loss 0.5890 val_acc 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [02:30<06:59,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 / 100 : Train Lost 0.5682 Train Acc 0.7137 val_loss 0.5848 val_acc 0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [02:34<06:40,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 100 : Train Lost 0.5664 Train Acc 0.7138 val_loss 0.5814 val_acc 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [02:39<06:27,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 / 100 : Train Lost 0.5604 Train Acc 0.7180 val_loss 0.5844 val_acc 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [02:44<06:16,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 / 100 : Train Lost 0.5561 Train Acc 0.7199 val_loss 0.5850 val_acc 0.6913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [02:48<06:06,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 100 : Train Lost 0.5526 Train Acc 0.7212 val_loss 0.5722 val_acc 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [02:53<05:56,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 100 : Train Lost 0.5476 Train Acc 0.7267 val_loss 0.5698 val_acc 0.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [02:58<05:51,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 / 100 : Train Lost 0.5441 Train Acc 0.7276 val_loss 0.5722 val_acc 0.7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [03:02<05:43,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 / 100 : Train Lost 0.5412 Train Acc 0.7279 val_loss 0.5674 val_acc 0.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [03:22<11:00,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 100 : Train Lost 0.5369 Train Acc 0.7320 val_loss 0.5707 val_acc 0.7053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [03:57<19:59, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 / 100 : Train Lost 0.5358 Train Acc 0.7322 val_loss 0.5640 val_acc 0.7097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [04:24<23:25, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 / 100 : Train Lost 0.5300 Train Acc 0.7367 val_loss 0.5623 val_acc 0.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [04:28<17:18, 15.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 100 : Train Lost 0.5288 Train Acc 0.7366 val_loss 0.5643 val_acc 0.7073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [05:01<23:11, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 / 100 : Train Lost 0.5253 Train Acc 0.7421 val_loss 0.5655 val_acc 0.7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [05:36<27:43, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 / 100 : Train Lost 0.5241 Train Acc 0.7424 val_loss 0.5594 val_acc 0.7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [06:11<30:47, 27.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 / 100 : Train Lost 0.5206 Train Acc 0.7410 val_loss 0.5623 val_acc 0.7133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [06:46<32:34, 30.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 100 : Train Lost 0.5197 Train Acc 0.7438 val_loss 0.5598 val_acc 0.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [06:58<26:10, 24.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 / 100 : Train Lost 0.5166 Train Acc 0.7464 val_loss 0.5566 val_acc 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [07:01<19:12, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 / 100 : Train Lost 0.5141 Train Acc 0.7467 val_loss 0.5593 val_acc 0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [07:05<14:28, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 100 : Train Lost 0.5117 Train Acc 0.7497 val_loss 0.5588 val_acc 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [07:10<11:30, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 / 100 : Train Lost 0.5098 Train Acc 0.7505 val_loss 0.5570 val_acc 0.7177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [07:36<15:43, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 / 100 : Train Lost 0.5091 Train Acc 0.7501 val_loss 0.5607 val_acc 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [07:40<11:59, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 100 : Train Lost 0.5065 Train Acc 0.7497 val_loss 0.5556 val_acc 0.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [07:46<09:57, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 100 : Train Lost 0.5044 Train Acc 0.7536 val_loss 0.5545 val_acc 0.7173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [07:52<08:27,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 / 100 : Train Lost 0.5015 Train Acc 0.7557 val_loss 0.5542 val_acc 0.7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [07:57<07:12,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 / 100 : Train Lost 0.5007 Train Acc 0.7578 val_loss 0.5549 val_acc 0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [08:01<06:11,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 100 : Train Lost 0.4997 Train Acc 0.7533 val_loss 0.5597 val_acc 0.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [08:34<13:10, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 / 100 : Train Lost 0.4989 Train Acc 0.7592 val_loss 0.5514 val_acc 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [09:12<19:05, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 / 100 : Train Lost 0.4961 Train Acc 0.7583 val_loss 0.5549 val_acc 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [09:50<22:59, 26.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 100 : Train Lost 0.4961 Train Acc 0.7579 val_loss 0.5564 val_acc 0.7137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [10:14<21:53, 25.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 / 100 : Train Lost 0.4940 Train Acc 0.7612 val_loss 0.5580 val_acc 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [10:18<15:53, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 / 100 : Train Lost 0.4918 Train Acc 0.7624 val_loss 0.5590 val_acc 0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [10:21<11:43, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 100 : Train Lost 0.4947 Train Acc 0.7602 val_loss 0.5534 val_acc 0.7187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [10:25<08:52, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 / 100 : Train Lost 0.4893 Train Acc 0.7625 val_loss 0.5594 val_acc 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [10:28<06:56,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 / 100 : Train Lost 0.4873 Train Acc 0.7636 val_loss 0.5573 val_acc 0.7160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [10:32<05:33,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 / 100 : Train Lost 0.4855 Train Acc 0.7650 val_loss 0.5540 val_acc 0.7187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [10:36<04:47,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 100 : Train Lost 0.4842 Train Acc 0.7662 val_loss 0.5547 val_acc 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [10:41<04:18,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 / 100 : Train Lost 0.4840 Train Acc 0.7686 val_loss 0.5542 val_acc 0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [10:45<03:55,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 / 100 : Train Lost 0.4850 Train Acc 0.7675 val_loss 0.5538 val_acc 0.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [10:50<03:41,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 100 : Train Lost 0.4804 Train Acc 0.7698 val_loss 0.5543 val_acc 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [10:55<03:30,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 / 100 : Train Lost 0.4794 Train Acc 0.7709 val_loss 0.5596 val_acc 0.7127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [11:00<03:21,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 / 100 : Train Lost 0.4780 Train Acc 0.7692 val_loss 0.5514 val_acc 0.7270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [11:04<03:12,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 / 100 : Train Lost 0.4797 Train Acc 0.7694 val_loss 0.5532 val_acc 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [11:21<05:15,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 100 : Train Lost 0.4764 Train Acc 0.7746 val_loss 0.5564 val_acc 0.7227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [11:56<10:03, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 / 100 : Train Lost 0.4764 Train Acc 0.7736 val_loss 0.5536 val_acc 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [12:02<07:56, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 / 100 : Train Lost 0.4742 Train Acc 0.7759 val_loss 0.5562 val_acc 0.7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [12:27<09:49, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 100 : Train Lost 0.4726 Train Acc 0.7745 val_loss 0.5610 val_acc 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [13:00<12:20, 21.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 / 100 : Train Lost 0.4715 Train Acc 0.7772 val_loss 0.5557 val_acc 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [13:36<14:17, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 / 100 : Train Lost 0.4728 Train Acc 0.7729 val_loss 0.5569 val_acc 0.7237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [14:10<15:10, 28.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 100 : Train Lost 0.4728 Train Acc 0.7743 val_loss 0.5555 val_acc 0.7190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [14:46<15:45, 30.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 / 100 : Train Lost 0.4694 Train Acc 0.7760 val_loss 0.5558 val_acc 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [15:18<15:36, 31.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 / 100 : Train Lost 0.4662 Train Acc 0.7805 val_loss 0.5569 val_acc 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [15:52<15:22, 31.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 / 100 : Train Lost 0.4655 Train Acc 0.7794 val_loss 0.5580 val_acc 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [16:24<14:54, 31.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 100 : Train Lost 0.4655 Train Acc 0.7784 val_loss 0.5571 val_acc 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [16:59<14:49, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 / 100 : Train Lost 0.4625 Train Acc 0.7819 val_loss 0.5606 val_acc 0.7227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [17:31<14:11, 32.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 / 100 : Train Lost 0.4632 Train Acc 0.7806 val_loss 0.5542 val_acc 0.7263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [17:37<10:12, 24.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 100 : Train Lost 0.4656 Train Acc 0.7808 val_loss 0.5546 val_acc 0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [17:41<07:22, 18.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 / 100 : Train Lost 0.4624 Train Acc 0.7816 val_loss 0.5581 val_acc 0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [17:45<05:22, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 / 100 : Train Lost 0.4589 Train Acc 0.7867 val_loss 0.5622 val_acc 0.7257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [17:50<04:10, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / 100 : Train Lost 0.4590 Train Acc 0.7863 val_loss 0.5613 val_acc 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [17:55<03:18,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / 100 : Train Lost 0.4592 Train Acc 0.7853 val_loss 0.5622 val_acc 0.7237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [18:00<02:43,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 / 100 : Train Lost 0.4557 Train Acc 0.7835 val_loss 0.5593 val_acc 0.7253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [18:05<04:31, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 / 100 : Train Lost 0.4577 Train Acc 0.7847 val_loss 0.5637 val_acc 0.7267\n",
      "Early stopped at Epoch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# GPU 활용 가능시 GPU 기반으로 LSTM 학습 루프 (BCEWithLogits + Adam + Early Stopping)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "\n",
    "# 매모리 캐시 정리\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()          # 이진분류 손실 (시그모이드 포함 logit 입력용)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# 시각화를 위한 loss 기록\n",
    "train_losses, val_losses, train_accs, val_accs = [], [] ,[], []\n",
    "\n",
    "# 조기종료 관련\n",
    "early_stopping_patience = 20\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    total_loss, correct, total = 0, 0, 0        # 누적 손실, 정답, 전체 샘플 수\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device).long()                 \n",
    "        labels = labels.to(device).float().view(-1, 1)   \n",
    "\n",
    "        optimizer.zero_grad()                   # 이전 배치 기울기 초기화\n",
    "        \n",
    "        output = model(inputs)                  # 순전파\n",
    "        loss = criterion(output, labels)        # 손실계산\n",
    "        loss.backward()                         # 역전파\n",
    "        optimizer.step()                        # 파라미터 업데이트\n",
    "\n",
    "        # 배치 로그\n",
    "        total_loss += loss.item()               # 배치 손실을 스칼라로 누적\n",
    "        p = torch.sigmoid(output)               # logit-> 0~1 확률로 변환\n",
    "        pred = (p >= 0.5).float()   \n",
    "        correct += (pred == labels).sum().item()        # 맞춘 개수\n",
    "        total += labels.size(0)                 # 배치 샘플 수\n",
    "\n",
    "    # 에폭 로그\n",
    "    train_loss = total_loss / len(train_dataloader)     # 에폭별 평균 학습 손실\n",
    "    train_losses.append(train_loss)     \n",
    "    train_acc = correct / total\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # 검증\n",
    "    model.eval()                                # 평가모드 (Dropout, BN 비활성화)\n",
    "    val_loss, val_correct, val_total = 0, 0, 0  # 누적 손실, 정답, 전체 샘플 수\n",
    "    with torch.no_grad():                       # 기울기 계산 비활성화\n",
    "        for val_inputs, val_labels in val_dataloader:\n",
    "            val_inputs = val_inputs.to(device).long()                 \n",
    "            val_labels = val_labels.to(device).float().view(-1, 1)   \n",
    "            output = model(val_inputs)\n",
    "            loss = criterion(output, val_labels)\n",
    "\n",
    "                    # 배치 로그\n",
    "            val_loss += loss.item()\n",
    "            p = torch.sigmoid(output)\n",
    "            pred = (p >= 0.5).float()\n",
    "            val_correct += (pred == val_labels).sum().item()\n",
    "            val_total += val_labels.size(0)\n",
    "\n",
    "        # 에폭 로그\n",
    "        val_loss = val_loss / len(val_dataloader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # 에폭 로그 출력\n",
    "        print(f'Epoch {epoch+1} / {epochs} : Train Loss {train_loss:.4f} Train Acc {train_acc:.4f} val_loss {val_loss:.4f} val_acc {val_acc:.4f}')\n",
    "\n",
    "        # 조기 종료\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter > early_stopping_patience:\n",
    "                print(f'Early stopped at Epoch {epoch + 1}')\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
