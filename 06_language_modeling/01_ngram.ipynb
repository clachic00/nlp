{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830da992",
   "metadata": {},
   "source": [
    "# n-gram 언어 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05227122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0167bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"오늘은 날씨가 좋다. 오늘은 기분이 좋다. 오늘은 일이 많다. 오늘은 사람이 많다. 오늘은 날씨가 맑다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81cbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce1e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('.', '오늘은'): 4,\n",
       "         ('오늘은', '날씨가'): 2,\n",
       "         ('좋다', '.'): 2,\n",
       "         ('많다', '.'): 2,\n",
       "         ('날씨가', '좋다'): 1,\n",
       "         ('오늘은', '기분이'): 1,\n",
       "         ('기분이', '좋다'): 1,\n",
       "         ('오늘은', '일이'): 1,\n",
       "         ('일이', '많다'): 1,\n",
       "         ('오늘은', '사람이'): 1,\n",
       "         ('사람이', '많다'): 1,\n",
       "         ('날씨가', '맑다'): 1,\n",
       "         ('맑다', '.'): 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-gram, 2-gram                                  # n-gram(연속된 n개 토큰 묶음) 만들 거임\n",
    "unigram = tokens                                   # 1-gram은 그냥 토큰 리스트 자체\n",
    "bigram = list(ngrams(tokens, 2))                   # 토큰을 2개씩 연속으로 묶은 (토큰1, 토큰2) bigram 리스트 생성\n",
    "\n",
    "unigram_freq = Counter(unigram)                    # 각 토큰(1-gram)이 몇 번 나왔는지 빈도 세기\n",
    "bigram_freq = Counter(bigram)                      # 각 bigram(2-gram 튜플)이 몇 번 나왔는지 빈도 세기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e34ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(날씨가|오늘은) = 0.400\n",
      "P(좋다|날씨가) = 0.500\n",
      "P(.|좋다) = 1.000\n",
      "P(오늘은|.) = 0.800\n",
      "P(기분이|오늘은) = 0.200\n",
      "P(좋다|기분이) = 1.000\n",
      "P(일이|오늘은) = 0.200\n",
      "P(많다|일이) = 1.000\n",
      "P(.|많다) = 1.000\n",
      "P(사람이|오늘은) = 0.200\n",
      "P(많다|사람이) = 1.000\n",
      "P(맑다|날씨가) = 0.500\n",
      "P(.|맑다) = 1.000\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), freq in bigram_freq.items():\n",
    "    prob = freq / unigram_freq[w1]      # 조건부 확률 계산 (w1 뒤에 w2가 올 확률)\n",
    "    print(f'P({w2}|{w1}) = {prob:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3fbda4",
   "metadata": {},
   "source": [
    "### Perplexity 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d0a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math                                           # 로그, 거듭제곱 계산용 수학 라이브러리\n",
    "\n",
    "# Perplexity의 평가 기준\n",
    "# - 모델이 테스트 데이터에서 얼마나 적은 불확실성을 가지며 다음 단어를 잘 예측하는가\n",
    "def compute_bigram_perplexity(test_text, unigram_freq, bigram_freq):  \n",
    "    test_tokens = nltk.word_tokenize(test_text)       # 테스트 문장을 토큰(단어) 단위로 분리\n",
    "    test_bigrams = list(ngrams(test_tokens, 2))       # 테스트 토큰으로부터 bigram 생성\n",
    "\n",
    "    log_prob_sum = 0                                  # 로그 확률 누적 합 초기화\n",
    "    N = len(test_bigrams)                             # 테스트 bigram 총 개수\n",
    "\n",
    "    for bigram in test_bigrams:                       # 각 bigram에 대해 반복\n",
    "        w1, w2 = bigram                               # bigram을 앞 단어(w1), 뒤 단어(w2)로 분리\n",
    "        prob = bigram_freq.get(bigram, 0) / unigram_freq.get(w1, 1)  \n",
    "                                                      # P(w2 | w1) = bigram 빈도 / unigram 빈도\n",
    "        if prob == 0:                                 # 확률이 0이면\n",
    "            prob = 1e-10                              # 로그 계산을 위해 아주 작은 값으로 대체\n",
    "        log_prob_sum += math.log2(prob)               # 확률의 log2 값을 누적\n",
    "\n",
    "    cross_entropy = -log_prob_sum / N                 # 평균 음의 로그 확률 = 크로스 엔트로피\n",
    "    perplexity = math.pow(2, cross_entropy)           # perplexity = 2^(cross entropy)\n",
    "\n",
    "    return perplexity                                 # 계산된 perplexity 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3676ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"자연어 처리는 재미있다. 자연어 처리는 어렵지만 도전하고 싶다. 오늘은 날씨가 좋다.\"  \n",
    "                                                    # 학습용 말뭉치(훈련 텍스트)\n",
    "\n",
    "train_tokens = nltk.word_tokenize(train_text)       # 문장을 단어(토큰) 단위로 분리\n",
    "\n",
    "unigram = train_tokens                              # 1-gram: 각 단어 토큰 그대로 사용\n",
    "bigrams = list(ngrams(train_tokens, 2))             # 2-gram: 연속된 두 단어씩 묶어 bigram 생성\n",
    "\n",
    "unigram_freq = Counter(unigram)                     # 각 단어(unigram)의 등장 횟수 계산\n",
    "bigrams_freq = Counter(bigrams)                     # 각 bigram(단어쌍)의 등장 횟수 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10c9213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자연어 처리는 재미있다. perplexity: 1.2599210498948732\n",
      "자연어 처리는 어렵지만 도전하고 싶다. perplexity: 1.148698354997035\n",
      "오늘은 날씨가 좋다. perplexity: 1.0\n",
      "기계 번역은 어렵다. perplexity: 10000000000.000008\n",
      "자연어 처리에 도전하고 싶다. perplexity: 100000.00000000003\n",
      "오늘 날씨가 흐리다. perplexity: 10000000000.000008\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [                                 # 퍼플렉서티를 평가할 테스트 문장 목록\n",
    "    \"자연어 처리는 재미있다.\",                      # 학습 데이터에 포함된 문장\n",
    "    \"자연어 처리는 어렵지만 도전하고 싶다.\",        # 학습 데이터와 유사한 문장\n",
    "    \"오늘은 날씨가 좋다.\",                          # 학습 데이터에 포함된 문장\n",
    "    \"기계 번역은 어렵다.\",                          # 학습 데이터에 없는 문장\n",
    "    \"자연어 처리에 도전하고 싶다.\",                 # 일부 단어/구조만 겹치는 문장\n",
    "    \"오늘 날씨가 흐리다.\"                           # 단어 순서·표현이 다른 문장\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:                     # 각 테스트 문장에 대해 반복\n",
    "    pp = compute_bigram_perplexity(\n",
    "        sentence,                                   # 평가할 문장\n",
    "        unigram_freq,                               # 학습된 unigram 빈도\n",
    "        bigrams_freq                                # 학습된 bigram 빈도\n",
    "    )\n",
    "    print(sentence, \"perplexity:\", pp)               # 문장과 해당 perplexity 출력\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
