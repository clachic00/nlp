{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8073f5ac",
   "metadata": {},
   "source": [
    "# ngram 기반의 간단한 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a9a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                         # 토큰화/전처리용\n",
    "from nltk.util import ngrams        # n-gram 생성함수\n",
    "from collections import Counter     # 빈도 집계용\n",
    "import random                       # 확률 샘플링 용도\n",
    "\n",
    "# 시드 단어에서 시작해 bigram 빈도 기반으로 다음 단어를 확률적으로 뽑아 문장을 생성하는 함수\n",
    "def generate_text_bigram(seed, unigram_freq, bigram_freq, max_len=10):\n",
    "    current_word = seed             # 현재 단어가 최초단어\n",
    "    gernerated = [current_word]     # 생성 결과 리스트 : 첫 단어는 seed\n",
    "    \n",
    "    for _ in range(max_len - 1):                                                # 이미 seed로 1개 포함되어 최대길이 -1\n",
    "        candidates = [(bigram, freq) for bigram, freq in bigram_freq.items()    # 가능한 다음 후보 수집\n",
    "                      if bigram[0] == current_word]                             # 현재 단어로 시작하는 bigram만 필터링\n",
    "        if not candidates:                                                      \n",
    "            break\n",
    "        \n",
    "        # 다음 단어와 빈도(freq)만 뽑아 두 리스트로 분리\n",
    "        words, freqs = zip(*[(bigram[1], freq) for bigram, freq in candidates])  \n",
    "        total = sum(freqs)                                                      \n",
    "        probs = [f / total for f in freqs]                                      # 빈도를 확률로 변환\n",
    "        \n",
    "        next_word = random.choices(words, weights=probs)[0]                     # 확률에 따라 다음 단어 1개 샘플링\n",
    "        gernerated.append(next_word)                                             \n",
    "        current_word = next_word                                                \n",
    "        \n",
    "    return \" \".join(gernerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb2c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "train_text = \"자연어 처리는 재미있다. 자연어 처리는 어렵지만 도전하고 싶다. 오늘은 날씨가 좋다.\"\n",
    "\n",
    "train_tokens = nltk.tokenize.word_tokenize(train_text)\n",
    "unigram = train_tokens\n",
    "bigram = list(nltk.bigrams(train_tokens))\n",
    "\n",
    "unigram_freq = Counter(unigram)\n",
    "bigram_freq = Counter(bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba88bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['자연어', '처리는', '재미있다', '.', '자연어', '처리는', '어렵지만', '도전하고', '싶다', '.', '오늘은', '날씨가', '좋다', '.']\n",
      "[('자연어', '처리는'), ('처리는', '재미있다'), ('재미있다', '.'), ('.', '자연어'), ('자연어', '처리는'), ('처리는', '어렵지만'), ('어렵지만', '도전하고'), ('도전하고', '싶다'), ('싶다', '.'), ('.', '오늘은'), ('오늘은', '날씨가'), ('날씨가', '좋다'), ('좋다', '.')]\n"
     ]
    }
   ],
   "source": [
    "# from itertools import pairwise\n",
    "\n",
    "unigram = train_tokens\n",
    "bigrams = list(ngrams(train_tokens, 2))   # 인접한 2개 토큰 묶음\n",
    "# bigrams = list(pairwise(train_tokens))\n",
    "\n",
    "print(unigram)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9043a4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.': 3, '자연어': 2, '처리는': 2, '재미있다': 1, '어렵지만': 1, '도전하고': 1, '싶다': 1, '오늘은': 1, '날씨가': 1, '좋다': 1})\n",
      "Counter({('자연어', '처리는'): 2, ('처리는', '재미있다'): 1, ('재미있다', '.'): 1, ('.', '자연어'): 1, ('처리는', '어렵지만'): 1, ('어렵지만', '도전하고'): 1, ('도전하고', '싶다'): 1, ('싶다', '.'): 1, ('.', '오늘은'): 1, ('오늘은', '날씨가'): 1, ('날씨가', '좋다'): 1, ('좋다', '.'): 1})\n"
     ]
    }
   ],
   "source": [
    "unigram_freq = Counter(unigram)         # 유니그램 빈도 집계\n",
    "bigrams_freq = Counter(bigrams)          # 바이그램 빈도 집계\n",
    "\n",
    "print(unigram_freq)\n",
    "print(bigrams_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50b97ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'자연어 처리는 재미있다 . 자연어 처리는 어렵지만 도전하고 싶다 . 오늘은 날씨가 좋다 . 자연어 처리는 어렵지만 도전하고 싶다 . 오늘은 날씨가 좋다 . 자연어 처리는 재미있다 . 오늘은 날씨가 좋다 . 자연어 처리는 재미있다 . 오늘은 날씨가 좋다 . 오늘은 날씨가 좋다 . 오늘은 날씨가 좋다 . 자연어 처리는 어렵지만 도전하고 싶다 . 자연어 처리는 재미있다 . 자연어 처리는 어렵지만 도전하고 싶다 . 자연어 처리는 재미있다 . 오늘은 날씨가 좋다 . 오늘은 날씨가 좋다 . 자연어 처리는 어렵지만 도전하고 싶다 . 자연어 처리는 어렵지만 도전하고 싶다 . 오늘은 날씨가 좋다 . 자연어 처리는 어렵지만 도전하고 싶다 . 오늘은 날씨가'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_bigram(\"자연어\", unigram_freq, bigrams_freq, max_len=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
